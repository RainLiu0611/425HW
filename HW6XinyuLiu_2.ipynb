{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f87b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a969f6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/96/4e/970cd3e13ad95aed81102272f0678d8cc48101880b8be5bae8aad22e7f3b/torch-2.2.0-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.2.0-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/3e/4f/ad5c2a7d2783649c8ea691441a9f285accae922a1625e21603c45e3ddff4/torchvision-0.17.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchvision-0.17.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/79/f7/5929802a1d14693d2dea6e60c51a923724348f134a91558f22bc686d3d8b/torchaudio-2.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchaudio-2.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /Users/rain/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /Users/rain/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/rain/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/rain/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/rain/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in /Users/rain/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/rain/anaconda3/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rain/anaconda3/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rain/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rain/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rain/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rain/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rain/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rain/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.0-cp311-none-macosx_11_0_arm64.whl (59.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.17.0-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: typing-extensions, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed torch-2.2.0 torchaudio-2.2.0 torchvision-0.17.0 typing-extensions-4.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82ca170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76940a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c7087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"card_transdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb0dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable and generate the training and test sets\n",
    "X_train = data.iloc[:500000,:7]\n",
    "X_test = data.iloc[500000:,:7]\n",
    "y_train = data.iloc[:500000,-1]\n",
    "y_test = data.iloc[500000:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f439ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data into a PyTorch Dataset class\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "# Update your Dataset and DataLoader accordingly\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12023444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Neural Network Architecture\n",
    "\n",
    "# Experiment with different batch sizes\n",
    "batch_size = 64 \n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # This might be unnecessary for already flattened input\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),  # Adjusted input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Consider removing if input is already flat\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Adjust the model instantiation accordingly\n",
    "input_size = 7  # Adjusted for your dataset\n",
    "num_classes = 10  # Assuming this is correct for your task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cd27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization Loop, here we can experiment with the parameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "# Hyperparameters\n",
    "hyperparams = {\n",
    "    'input_size': X_train.shape[1],\n",
    "    'hidden_size': 64,  # we can experiment with this\n",
    "    'batch_size': 64,   # we can experiment with this\n",
    "    'learning_rate': 0.01,  # we can experiment with this\n",
    "    'num_epochs': 10   # we can experiment with this\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853298d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=hyperparams[\"batch_size\"], shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=hyperparams[\"batch_size\"], shuffle=False)\n",
    "model = NeuralNetwork(hyperparams[\"input_size\"], hyperparams[\"hidden_size\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59db6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=hyperparams[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa631cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full implementation\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdcb8245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.197701  [   64/500000]\n",
      "loss: 0.584439  [ 6464/500000]\n",
      "loss: 0.515197  [12864/500000]\n",
      "loss: 0.521941  [19264/500000]\n",
      "loss: 0.311586  [25664/500000]\n",
      "loss: 0.542169  [32064/500000]\n",
      "loss: 0.226477  [38464/500000]\n",
      "loss: 0.414987  [44864/500000]\n",
      "loss: 0.269992  [51264/500000]\n",
      "loss: 0.264687  [57664/500000]\n",
      "loss: 0.174859  [64064/500000]\n",
      "loss: 0.337666  [70464/500000]\n",
      "loss: 1.085082  [76864/500000]\n",
      "loss: 0.147570  [83264/500000]\n",
      "loss: 0.288419  [89664/500000]\n",
      "loss: 0.311441  [96064/500000]\n",
      "loss: 0.308966  [102464/500000]\n",
      "loss: 0.147722  [108864/500000]\n",
      "loss: 0.179376  [115264/500000]\n",
      "loss: 0.121280  [121664/500000]\n",
      "loss: 0.257264  [128064/500000]\n",
      "loss: 0.228659  [134464/500000]\n",
      "loss: 0.267845  [140864/500000]\n",
      "loss: 0.064499  [147264/500000]\n",
      "loss: 0.092105  [153664/500000]\n",
      "loss: 0.184127  [160064/500000]\n",
      "loss: 0.159294  [166464/500000]\n",
      "loss: 0.151893  [172864/500000]\n",
      "loss: 0.099691  [179264/500000]\n",
      "loss: 0.388206  [185664/500000]\n",
      "loss: 0.112199  [192064/500000]\n",
      "loss: 0.143298  [198464/500000]\n",
      "loss: 0.278252  [204864/500000]\n",
      "loss: 0.151989  [211264/500000]\n",
      "loss: 0.132364  [217664/500000]\n",
      "loss: 0.129968  [224064/500000]\n",
      "loss: 0.160411  [230464/500000]\n",
      "loss: 0.081111  [236864/500000]\n",
      "loss: 0.057025  [243264/500000]\n",
      "loss: 0.151584  [249664/500000]\n",
      "loss: 0.085031  [256064/500000]\n",
      "loss: 0.123906  [262464/500000]\n",
      "loss: 0.200922  [268864/500000]\n",
      "loss: 0.077847  [275264/500000]\n",
      "loss: 0.098684  [281664/500000]\n",
      "loss: 0.106868  [288064/500000]\n",
      "loss: 0.127445  [294464/500000]\n",
      "loss: 0.113373  [300864/500000]\n",
      "loss: 0.070446  [307264/500000]\n",
      "loss: 0.087508  [313664/500000]\n",
      "loss: 0.149661  [320064/500000]\n",
      "loss: 0.188061  [326464/500000]\n",
      "loss: 0.194917  [332864/500000]\n",
      "loss: 0.166521  [339264/500000]\n",
      "loss: 0.087531  [345664/500000]\n",
      "loss: 0.103921  [352064/500000]\n",
      "loss: 0.128251  [358464/500000]\n",
      "loss: 0.107654  [364864/500000]\n",
      "loss: 0.105796  [371264/500000]\n",
      "loss: 0.064978  [377664/500000]\n",
      "loss: 0.125962  [384064/500000]\n",
      "loss: 0.106154  [390464/500000]\n",
      "loss: 0.116131  [396864/500000]\n",
      "loss: 0.103613  [403264/500000]\n",
      "loss: 0.085974  [409664/500000]\n",
      "loss: 0.099626  [416064/500000]\n",
      "loss: 0.115624  [422464/500000]\n",
      "loss: 0.095242  [428864/500000]\n",
      "loss: 0.080991  [435264/500000]\n",
      "loss: 0.170243  [441664/500000]\n",
      "loss: 0.056590  [448064/500000]\n",
      "loss: 0.066820  [454464/500000]\n",
      "loss: 0.063802  [460864/500000]\n",
      "loss: 0.115546  [467264/500000]\n",
      "loss: 0.110669  [473664/500000]\n",
      "loss: 0.077537  [480064/500000]\n",
      "loss: 0.081167  [486464/500000]\n",
      "loss: 0.125828  [492864/500000]\n",
      "loss: 0.089318  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.096874 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.097507  [   64/500000]\n",
      "loss: 0.028738  [ 6464/500000]\n",
      "loss: 0.146039  [12864/500000]\n",
      "loss: 0.160449  [19264/500000]\n",
      "loss: 0.097248  [25664/500000]\n",
      "loss: 0.059514  [32064/500000]\n",
      "loss: 0.150914  [38464/500000]\n",
      "loss: 0.008736  [44864/500000]\n",
      "loss: 0.104893  [51264/500000]\n",
      "loss: 0.066344  [57664/500000]\n",
      "loss: 0.079830  [64064/500000]\n",
      "loss: 0.103126  [70464/500000]\n",
      "loss: 0.089695  [76864/500000]\n",
      "loss: 0.045963  [83264/500000]\n",
      "loss: 0.117641  [89664/500000]\n",
      "loss: 0.066279  [96064/500000]\n",
      "loss: 0.132673  [102464/500000]\n",
      "loss: 0.026193  [108864/500000]\n",
      "loss: 0.085652  [115264/500000]\n",
      "loss: 0.089085  [121664/500000]\n",
      "loss: 0.124150  [128064/500000]\n",
      "loss: 0.087245  [134464/500000]\n",
      "loss: 0.073265  [140864/500000]\n",
      "loss: 0.029323  [147264/500000]\n",
      "loss: 0.100037  [153664/500000]\n",
      "loss: 0.062586  [160064/500000]\n",
      "loss: 0.087119  [166464/500000]\n",
      "loss: 0.108120  [172864/500000]\n",
      "loss: 0.120668  [179264/500000]\n",
      "loss: 0.067140  [185664/500000]\n",
      "loss: 0.105329  [192064/500000]\n",
      "loss: 0.087260  [198464/500000]\n",
      "loss: 0.051258  [204864/500000]\n",
      "loss: 0.110974  [211264/500000]\n",
      "loss: 0.125366  [217664/500000]\n",
      "loss: 0.015518  [224064/500000]\n",
      "loss: 0.086368  [230464/500000]\n",
      "loss: 0.129764  [236864/500000]\n",
      "loss: 0.118126  [243264/500000]\n",
      "loss: 0.055206  [249664/500000]\n",
      "loss: 0.076565  [256064/500000]\n",
      "loss: 0.137944  [262464/500000]\n",
      "loss: 0.098739  [268864/500000]\n",
      "loss: 0.052349  [275264/500000]\n",
      "loss: 0.052028  [281664/500000]\n",
      "loss: 0.066191  [288064/500000]\n",
      "loss: 0.072869  [294464/500000]\n",
      "loss: 0.119332  [300864/500000]\n",
      "loss: 0.088600  [307264/500000]\n",
      "loss: 0.086663  [313664/500000]\n",
      "loss: 0.114171  [320064/500000]\n",
      "loss: 0.057962  [326464/500000]\n",
      "loss: 0.066875  [332864/500000]\n",
      "loss: 0.070248  [339264/500000]\n",
      "loss: 0.238482  [345664/500000]\n",
      "loss: 0.113709  [352064/500000]\n",
      "loss: 0.109856  [358464/500000]\n",
      "loss: 0.055926  [364864/500000]\n",
      "loss: 0.072822  [371264/500000]\n",
      "loss: 0.117640  [377664/500000]\n",
      "loss: 0.045792  [384064/500000]\n",
      "loss: 0.074015  [390464/500000]\n",
      "loss: 0.015551  [396864/500000]\n",
      "loss: 0.257534  [403264/500000]\n",
      "loss: 0.126257  [409664/500000]\n",
      "loss: 0.070809  [416064/500000]\n",
      "loss: 0.106665  [422464/500000]\n",
      "loss: 0.072022  [428864/500000]\n",
      "loss: 0.053384  [435264/500000]\n",
      "loss: 0.099206  [441664/500000]\n",
      "loss: 0.043024  [448064/500000]\n",
      "loss: 0.080411  [454464/500000]\n",
      "loss: 0.078483  [460864/500000]\n",
      "loss: 0.061701  [467264/500000]\n",
      "loss: 0.063536  [473664/500000]\n",
      "loss: 0.060763  [480064/500000]\n",
      "loss: 0.039464  [486464/500000]\n",
      "loss: 0.009068  [492864/500000]\n",
      "loss: 0.070415  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.087053 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.054703  [   64/500000]\n",
      "loss: 0.058698  [ 6464/500000]\n",
      "loss: 0.088337  [12864/500000]\n",
      "loss: 0.088634  [19264/500000]\n",
      "loss: 0.120633  [25664/500000]\n",
      "loss: 0.079884  [32064/500000]\n",
      "loss: 0.076078  [38464/500000]\n",
      "loss: 0.114691  [44864/500000]\n",
      "loss: 0.081730  [51264/500000]\n",
      "loss: 0.056163  [57664/500000]\n",
      "loss: 0.066584  [64064/500000]\n",
      "loss: 0.149516  [70464/500000]\n",
      "loss: 0.086705  [76864/500000]\n",
      "loss: 0.040415  [83264/500000]\n",
      "loss: 0.037882  [89664/500000]\n",
      "loss: 0.174644  [96064/500000]\n",
      "loss: 0.015832  [102464/500000]\n",
      "loss: 0.057536  [108864/500000]\n",
      "loss: 0.050865  [115264/500000]\n",
      "loss: 0.033702  [121664/500000]\n",
      "loss: 0.095361  [128064/500000]\n",
      "loss: 0.052512  [134464/500000]\n",
      "loss: 0.061469  [140864/500000]\n",
      "loss: 0.067415  [147264/500000]\n",
      "loss: 0.020855  [153664/500000]\n",
      "loss: 0.032495  [160064/500000]\n",
      "loss: 0.067777  [166464/500000]\n",
      "loss: 0.037294  [172864/500000]\n",
      "loss: 0.023102  [179264/500000]\n",
      "loss: 0.046785  [185664/500000]\n",
      "loss: 0.052908  [192064/500000]\n",
      "loss: 0.116884  [198464/500000]\n",
      "loss: 0.068547  [204864/500000]\n",
      "loss: 0.019176  [211264/500000]\n",
      "loss: 0.266707  [217664/500000]\n",
      "loss: 0.091539  [224064/500000]\n",
      "loss: 0.047417  [230464/500000]\n",
      "loss: 0.101950  [236864/500000]\n",
      "loss: 0.029001  [243264/500000]\n",
      "loss: 0.191826  [249664/500000]\n",
      "loss: 0.146997  [256064/500000]\n",
      "loss: 0.084049  [262464/500000]\n",
      "loss: 0.105884  [268864/500000]\n",
      "loss: 0.076551  [275264/500000]\n",
      "loss: 0.036982  [281664/500000]\n",
      "loss: 0.095502  [288064/500000]\n",
      "loss: 0.069403  [294464/500000]\n",
      "loss: 0.030481  [300864/500000]\n",
      "loss: 0.127338  [307264/500000]\n",
      "loss: 0.025696  [313664/500000]\n",
      "loss: 0.068572  [320064/500000]\n",
      "loss: 0.099093  [326464/500000]\n",
      "loss: 0.068861  [332864/500000]\n",
      "loss: 0.021686  [339264/500000]\n",
      "loss: 0.106600  [345664/500000]\n",
      "loss: 0.095820  [352064/500000]\n",
      "loss: 0.063626  [358464/500000]\n",
      "loss: 0.030169  [364864/500000]\n",
      "loss: 0.090321  [371264/500000]\n",
      "loss: 0.131647  [377664/500000]\n",
      "loss: 0.061113  [384064/500000]\n",
      "loss: 0.015059  [390464/500000]\n",
      "loss: 0.023798  [396864/500000]\n",
      "loss: 0.175181  [403264/500000]\n",
      "loss: 0.127542  [409664/500000]\n",
      "loss: 0.093182  [416064/500000]\n",
      "loss: 0.027541  [422464/500000]\n",
      "loss: 0.065881  [428864/500000]\n",
      "loss: 0.113835  [435264/500000]\n",
      "loss: 0.071337  [441664/500000]\n",
      "loss: 0.039112  [448064/500000]\n",
      "loss: 0.087247  [454464/500000]\n",
      "loss: 0.046747  [460864/500000]\n",
      "loss: 0.131750  [467264/500000]\n",
      "loss: 0.051473  [473664/500000]\n",
      "loss: 0.082157  [480064/500000]\n",
      "loss: 0.068849  [486464/500000]\n",
      "loss: 0.046754  [492864/500000]\n",
      "loss: 0.073561  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.073480 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.049565  [   64/500000]\n",
      "loss: 0.089251  [ 6464/500000]\n",
      "loss: 0.074600  [12864/500000]\n",
      "loss: 0.043466  [19264/500000]\n",
      "loss: 0.063388  [25664/500000]\n",
      "loss: 0.065627  [32064/500000]\n",
      "loss: 0.040109  [38464/500000]\n",
      "loss: 0.012604  [44864/500000]\n",
      "loss: 0.118689  [51264/500000]\n",
      "loss: 0.132203  [57664/500000]\n",
      "loss: 0.054687  [64064/500000]\n",
      "loss: 0.050721  [70464/500000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.072709  [76864/500000]\n",
      "loss: 0.097480  [83264/500000]\n",
      "loss: 0.091192  [89664/500000]\n",
      "loss: 0.035251  [96064/500000]\n",
      "loss: 0.054417  [102464/500000]\n",
      "loss: 0.090423  [108864/500000]\n",
      "loss: 0.022432  [115264/500000]\n",
      "loss: 0.066504  [121664/500000]\n",
      "loss: 0.151831  [128064/500000]\n",
      "loss: 0.081101  [134464/500000]\n",
      "loss: 0.040976  [140864/500000]\n",
      "loss: 0.067793  [147264/500000]\n",
      "loss: 0.115658  [153664/500000]\n",
      "loss: 0.058660  [160064/500000]\n",
      "loss: 0.076652  [166464/500000]\n",
      "loss: 0.059741  [172864/500000]\n",
      "loss: 0.090508  [179264/500000]\n",
      "loss: 0.061917  [185664/500000]\n",
      "loss: 0.112633  [192064/500000]\n",
      "loss: 0.151178  [198464/500000]\n",
      "loss: 0.047659  [204864/500000]\n",
      "loss: 0.053396  [211264/500000]\n",
      "loss: 0.069363  [217664/500000]\n",
      "loss: 0.026033  [224064/500000]\n",
      "loss: 0.070944  [230464/500000]\n",
      "loss: 0.053260  [236864/500000]\n",
      "loss: 0.076281  [243264/500000]\n",
      "loss: 0.049538  [249664/500000]\n",
      "loss: 0.084538  [256064/500000]\n",
      "loss: 0.060888  [262464/500000]\n",
      "loss: 0.022050  [268864/500000]\n",
      "loss: 0.058906  [275264/500000]\n",
      "loss: 0.023303  [281664/500000]\n",
      "loss: 0.039820  [288064/500000]\n",
      "loss: 0.048820  [294464/500000]\n",
      "loss: 0.155483  [300864/500000]\n",
      "loss: 0.030176  [307264/500000]\n",
      "loss: 0.051798  [313664/500000]\n",
      "loss: 0.086005  [320064/500000]\n",
      "loss: 0.055064  [326464/500000]\n",
      "loss: 0.112366  [332864/500000]\n",
      "loss: 0.084413  [339264/500000]\n",
      "loss: 0.069700  [345664/500000]\n",
      "loss: 0.044278  [352064/500000]\n",
      "loss: 0.057659  [358464/500000]\n",
      "loss: 0.080536  [364864/500000]\n",
      "loss: 0.015839  [371264/500000]\n",
      "loss: 0.046805  [377664/500000]\n",
      "loss: 0.073571  [384064/500000]\n",
      "loss: 0.054729  [390464/500000]\n",
      "loss: 0.090669  [396864/500000]\n",
      "loss: 0.038695  [403264/500000]\n",
      "loss: 0.021871  [409664/500000]\n",
      "loss: 0.095577  [416064/500000]\n",
      "loss: 0.009993  [422464/500000]\n",
      "loss: 0.036455  [428864/500000]\n",
      "loss: 0.075407  [435264/500000]\n",
      "loss: 0.115938  [441664/500000]\n",
      "loss: 0.076243  [448064/500000]\n",
      "loss: 0.023604  [454464/500000]\n",
      "loss: 0.096659  [460864/500000]\n",
      "loss: 0.044203  [467264/500000]\n",
      "loss: 0.103864  [473664/500000]\n",
      "loss: 0.082758  [480064/500000]\n",
      "loss: 0.101440  [486464/500000]\n",
      "loss: 0.059035  [492864/500000]\n",
      "loss: 0.124510  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.054657 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.033453  [   64/500000]\n",
      "loss: 0.021244  [ 6464/500000]\n",
      "loss: 0.069550  [12864/500000]\n",
      "loss: 0.022173  [19264/500000]\n",
      "loss: 0.020420  [25664/500000]\n",
      "loss: 0.091577  [32064/500000]\n",
      "loss: 0.058236  [38464/500000]\n",
      "loss: 0.140090  [44864/500000]\n",
      "loss: 0.138280  [51264/500000]\n",
      "loss: 0.104750  [57664/500000]\n",
      "loss: 0.028700  [64064/500000]\n",
      "loss: 0.082855  [70464/500000]\n",
      "loss: 0.059415  [76864/500000]\n",
      "loss: 0.037832  [83264/500000]\n",
      "loss: 0.086053  [89664/500000]\n",
      "loss: 0.061765  [96064/500000]\n",
      "loss: 0.248009  [102464/500000]\n",
      "loss: 0.092588  [108864/500000]\n",
      "loss: 0.084076  [115264/500000]\n",
      "loss: 0.058236  [121664/500000]\n",
      "loss: 0.040406  [128064/500000]\n",
      "loss: 0.054640  [134464/500000]\n",
      "loss: 0.036996  [140864/500000]\n",
      "loss: 0.113089  [147264/500000]\n",
      "loss: 0.078105  [153664/500000]\n",
      "loss: 0.166783  [160064/500000]\n",
      "loss: 0.146955  [166464/500000]\n",
      "loss: 0.018531  [172864/500000]\n",
      "loss: 0.024908  [179264/500000]\n",
      "loss: 0.095549  [185664/500000]\n",
      "loss: 0.021280  [192064/500000]\n",
      "loss: 0.105308  [198464/500000]\n",
      "loss: 0.016022  [204864/500000]\n",
      "loss: 0.196162  [211264/500000]\n",
      "loss: 0.118158  [217664/500000]\n",
      "loss: 0.054312  [224064/500000]\n",
      "loss: 0.103677  [230464/500000]\n",
      "loss: 0.043919  [236864/500000]\n",
      "loss: 0.054079  [243264/500000]\n",
      "loss: 0.063189  [249664/500000]\n",
      "loss: 0.064834  [256064/500000]\n",
      "loss: 0.049395  [262464/500000]\n",
      "loss: 0.047338  [268864/500000]\n",
      "loss: 0.065843  [275264/500000]\n",
      "loss: 0.088861  [281664/500000]\n",
      "loss: 0.100246  [288064/500000]\n",
      "loss: 0.083145  [294464/500000]\n",
      "loss: 0.031056  [300864/500000]\n",
      "loss: 0.042531  [307264/500000]\n",
      "loss: 0.051903  [313664/500000]\n",
      "loss: 0.092554  [320064/500000]\n",
      "loss: 0.101568  [326464/500000]\n",
      "loss: 0.046543  [332864/500000]\n",
      "loss: 0.109476  [339264/500000]\n",
      "loss: 0.031907  [345664/500000]\n",
      "loss: 0.057121  [352064/500000]\n",
      "loss: 0.010661  [358464/500000]\n",
      "loss: 0.038202  [364864/500000]\n",
      "loss: 0.022413  [371264/500000]\n",
      "loss: 0.074584  [377664/500000]\n",
      "loss: 0.092474  [384064/500000]\n",
      "loss: 0.020027  [390464/500000]\n",
      "loss: 0.034352  [396864/500000]\n",
      "loss: 0.022593  [403264/500000]\n",
      "loss: 0.125276  [409664/500000]\n",
      "loss: 0.060671  [416064/500000]\n",
      "loss: 0.030017  [422464/500000]\n",
      "loss: 0.017226  [428864/500000]\n",
      "loss: 0.053738  [435264/500000]\n",
      "loss: 0.083090  [441664/500000]\n",
      "loss: 0.068216  [448064/500000]\n",
      "loss: 0.037025  [454464/500000]\n",
      "loss: 0.010179  [460864/500000]\n",
      "loss: 0.019946  [467264/500000]\n",
      "loss: 0.064080  [473664/500000]\n",
      "loss: 0.037465  [480064/500000]\n",
      "loss: 0.049381  [486464/500000]\n",
      "loss: 0.033395  [492864/500000]\n",
      "loss: 0.032465  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.089907 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.002647  [   64/500000]\n",
      "loss: 0.024007  [ 6464/500000]\n",
      "loss: 0.099913  [12864/500000]\n",
      "loss: 0.021224  [19264/500000]\n",
      "loss: 0.116074  [25664/500000]\n",
      "loss: 0.037286  [32064/500000]\n",
      "loss: 0.024583  [38464/500000]\n",
      "loss: 0.057368  [44864/500000]\n",
      "loss: 0.035622  [51264/500000]\n",
      "loss: 0.080272  [57664/500000]\n",
      "loss: 0.065080  [64064/500000]\n",
      "loss: 0.064268  [70464/500000]\n",
      "loss: 0.055031  [76864/500000]\n",
      "loss: 0.110932  [83264/500000]\n",
      "loss: 0.092834  [89664/500000]\n",
      "loss: 0.068298  [96064/500000]\n",
      "loss: 0.033985  [102464/500000]\n",
      "loss: 0.097326  [108864/500000]\n",
      "loss: 0.041116  [115264/500000]\n",
      "loss: 0.047604  [121664/500000]\n",
      "loss: 0.088635  [128064/500000]\n",
      "loss: 0.072673  [134464/500000]\n",
      "loss: 0.027260  [140864/500000]\n",
      "loss: 0.040909  [147264/500000]\n",
      "loss: 0.055456  [153664/500000]\n",
      "loss: 0.046971  [160064/500000]\n",
      "loss: 0.066107  [166464/500000]\n",
      "loss: 0.086300  [172864/500000]\n",
      "loss: 0.087168  [179264/500000]\n",
      "loss: 0.041180  [185664/500000]\n",
      "loss: 0.066142  [192064/500000]\n",
      "loss: 0.107112  [198464/500000]\n",
      "loss: 0.104462  [204864/500000]\n",
      "loss: 0.075879  [211264/500000]\n",
      "loss: 0.034922  [217664/500000]\n",
      "loss: 0.058095  [224064/500000]\n",
      "loss: 0.058288  [230464/500000]\n",
      "loss: 0.022225  [236864/500000]\n",
      "loss: 0.024500  [243264/500000]\n",
      "loss: 0.040240  [249664/500000]\n",
      "loss: 0.057705  [256064/500000]\n",
      "loss: 0.037031  [262464/500000]\n",
      "loss: 0.058974  [268864/500000]\n",
      "loss: 0.080576  [275264/500000]\n",
      "loss: 0.038504  [281664/500000]\n",
      "loss: 0.055208  [288064/500000]\n",
      "loss: 0.055274  [294464/500000]\n",
      "loss: 0.105889  [300864/500000]\n",
      "loss: 0.101256  [307264/500000]\n",
      "loss: 0.029310  [313664/500000]\n",
      "loss: 0.022761  [320064/500000]\n",
      "loss: 0.042690  [326464/500000]\n",
      "loss: 0.323304  [332864/500000]\n",
      "loss: 0.058589  [339264/500000]\n",
      "loss: 0.060931  [345664/500000]\n",
      "loss: 0.022834  [352064/500000]\n",
      "loss: 0.023373  [358464/500000]\n",
      "loss: 0.043889  [364864/500000]\n",
      "loss: 0.014200  [371264/500000]\n",
      "loss: 0.048091  [377664/500000]\n",
      "loss: 0.072132  [384064/500000]\n",
      "loss: 0.069181  [390464/500000]\n",
      "loss: 0.044828  [396864/500000]\n",
      "loss: 0.024110  [403264/500000]\n",
      "loss: 0.122818  [409664/500000]\n",
      "loss: 0.067945  [416064/500000]\n",
      "loss: 0.025741  [422464/500000]\n",
      "loss: 0.346090  [428864/500000]\n",
      "loss: 0.064852  [435264/500000]\n",
      "loss: 0.083705  [441664/500000]\n",
      "loss: 0.049133  [448064/500000]\n",
      "loss: 0.083684  [454464/500000]\n",
      "loss: 0.120135  [460864/500000]\n",
      "loss: 0.023817  [467264/500000]\n",
      "loss: 0.060075  [473664/500000]\n",
      "loss: 0.047276  [480064/500000]\n",
      "loss: 0.040393  [486464/500000]\n",
      "loss: 0.039657  [492864/500000]\n",
      "loss: 0.106793  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.056369 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.069265  [   64/500000]\n",
      "loss: 0.031205  [ 6464/500000]\n",
      "loss: 0.042300  [12864/500000]\n",
      "loss: 0.034991  [19264/500000]\n",
      "loss: 0.038579  [25664/500000]\n",
      "loss: 0.071421  [32064/500000]\n",
      "loss: 0.063022  [38464/500000]\n",
      "loss: 0.009774  [44864/500000]\n",
      "loss: 0.064860  [51264/500000]\n",
      "loss: 0.044942  [57664/500000]\n",
      "loss: 0.047312  [64064/500000]\n",
      "loss: 0.036248  [70464/500000]\n",
      "loss: 0.046571  [76864/500000]\n",
      "loss: 0.065204  [83264/500000]\n",
      "loss: 0.009287  [89664/500000]\n",
      "loss: 0.031704  [96064/500000]\n",
      "loss: 0.080582  [102464/500000]\n",
      "loss: 0.105181  [108864/500000]\n",
      "loss: 0.257772  [115264/500000]\n",
      "loss: 0.024103  [121664/500000]\n",
      "loss: 0.047520  [128064/500000]\n",
      "loss: 0.027808  [134464/500000]\n",
      "loss: 0.047055  [140864/500000]\n",
      "loss: 0.039490  [147264/500000]\n",
      "loss: 0.038102  [153664/500000]\n",
      "loss: 0.065921  [160064/500000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.048557  [166464/500000]\n",
      "loss: 0.044173  [172864/500000]\n",
      "loss: 0.071646  [179264/500000]\n",
      "loss: 0.005184  [185664/500000]\n",
      "loss: 0.037637  [192064/500000]\n",
      "loss: 0.032813  [198464/500000]\n",
      "loss: 0.082979  [204864/500000]\n",
      "loss: 0.052850  [211264/500000]\n",
      "loss: 0.098852  [217664/500000]\n",
      "loss: 0.041914  [224064/500000]\n",
      "loss: 0.034572  [230464/500000]\n",
      "loss: 0.047776  [236864/500000]\n",
      "loss: 0.018633  [243264/500000]\n",
      "loss: 0.069881  [249664/500000]\n",
      "loss: 0.049926  [256064/500000]\n",
      "loss: 0.026579  [262464/500000]\n",
      "loss: 0.019739  [268864/500000]\n",
      "loss: 0.052603  [275264/500000]\n",
      "loss: 0.131870  [281664/500000]\n",
      "loss: 0.033346  [288064/500000]\n",
      "loss: 0.092484  [294464/500000]\n",
      "loss: 0.037806  [300864/500000]\n",
      "loss: 0.050001  [307264/500000]\n",
      "loss: 0.065598  [313664/500000]\n",
      "loss: 0.043827  [320064/500000]\n",
      "loss: 0.027051  [326464/500000]\n",
      "loss: 0.038352  [332864/500000]\n",
      "loss: 0.045273  [339264/500000]\n",
      "loss: 0.053637  [345664/500000]\n",
      "loss: 0.076132  [352064/500000]\n",
      "loss: 0.070247  [358464/500000]\n",
      "loss: 0.113859  [364864/500000]\n",
      "loss: 0.045293  [371264/500000]\n",
      "loss: 0.052761  [377664/500000]\n",
      "loss: 0.006815  [384064/500000]\n",
      "loss: 0.111042  [390464/500000]\n",
      "loss: 0.048067  [396864/500000]\n",
      "loss: 0.022794  [403264/500000]\n",
      "loss: 0.461359  [409664/500000]\n",
      "loss: 0.100401  [416064/500000]\n",
      "loss: 0.034403  [422464/500000]\n",
      "loss: 0.025142  [428864/500000]\n",
      "loss: 0.087726  [435264/500000]\n",
      "loss: 0.116663  [441664/500000]\n",
      "loss: 0.055382  [448064/500000]\n",
      "loss: 0.070318  [454464/500000]\n",
      "loss: 0.095792  [460864/500000]\n",
      "loss: 0.096308  [467264/500000]\n",
      "loss: 0.130889  [473664/500000]\n",
      "loss: 0.091525  [480064/500000]\n",
      "loss: 0.056438  [486464/500000]\n",
      "loss: 0.036017  [492864/500000]\n",
      "loss: 0.034539  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.068144 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.108678  [   64/500000]\n",
      "loss: 0.054807  [ 6464/500000]\n",
      "loss: 0.024737  [12864/500000]\n",
      "loss: 0.055704  [19264/500000]\n",
      "loss: 0.042133  [25664/500000]\n",
      "loss: 0.068452  [32064/500000]\n",
      "loss: 0.088019  [38464/500000]\n",
      "loss: 0.055260  [44864/500000]\n",
      "loss: 0.067374  [51264/500000]\n",
      "loss: 0.083216  [57664/500000]\n",
      "loss: 0.017894  [64064/500000]\n",
      "loss: 0.020841  [70464/500000]\n",
      "loss: 0.246732  [76864/500000]\n",
      "loss: 0.023101  [83264/500000]\n",
      "loss: 0.085441  [89664/500000]\n",
      "loss: 0.046287  [96064/500000]\n",
      "loss: 0.065544  [102464/500000]\n",
      "loss: 0.034774  [108864/500000]\n",
      "loss: 0.036046  [115264/500000]\n",
      "loss: 0.034930  [121664/500000]\n",
      "loss: 0.059064  [128064/500000]\n",
      "loss: 0.026949  [134464/500000]\n",
      "loss: 0.082451  [140864/500000]\n",
      "loss: 0.047912  [147264/500000]\n",
      "loss: 0.070583  [153664/500000]\n",
      "loss: 0.076439  [160064/500000]\n",
      "loss: 0.044405  [166464/500000]\n",
      "loss: 0.027818  [172864/500000]\n",
      "loss: 0.052774  [179264/500000]\n",
      "loss: 0.057644  [185664/500000]\n",
      "loss: 0.138029  [192064/500000]\n",
      "loss: 0.051876  [198464/500000]\n",
      "loss: 0.059093  [204864/500000]\n",
      "loss: 0.099979  [211264/500000]\n",
      "loss: 0.091942  [217664/500000]\n",
      "loss: 0.029161  [224064/500000]\n",
      "loss: 0.023281  [230464/500000]\n",
      "loss: 0.042824  [236864/500000]\n",
      "loss: 0.037551  [243264/500000]\n",
      "loss: 0.076876  [249664/500000]\n",
      "loss: 0.018392  [256064/500000]\n",
      "loss: 0.048828  [262464/500000]\n",
      "loss: 0.064718  [268864/500000]\n",
      "loss: 0.077313  [275264/500000]\n",
      "loss: 0.084425  [281664/500000]\n",
      "loss: 0.129196  [288064/500000]\n",
      "loss: 0.049355  [294464/500000]\n",
      "loss: 0.038615  [300864/500000]\n",
      "loss: 0.025747  [307264/500000]\n",
      "loss: 0.067862  [313664/500000]\n",
      "loss: 0.068902  [320064/500000]\n",
      "loss: 0.058035  [326464/500000]\n",
      "loss: 0.032745  [332864/500000]\n",
      "loss: 0.014028  [339264/500000]\n",
      "loss: 0.051435  [345664/500000]\n",
      "loss: 0.069157  [352064/500000]\n",
      "loss: 0.034899  [358464/500000]\n",
      "loss: 0.031772  [364864/500000]\n",
      "loss: 0.033145  [371264/500000]\n",
      "loss: 0.048967  [377664/500000]\n",
      "loss: 0.011271  [384064/500000]\n",
      "loss: 0.048668  [390464/500000]\n",
      "loss: 0.059718  [396864/500000]\n",
      "loss: 0.146271  [403264/500000]\n",
      "loss: 0.030758  [409664/500000]\n",
      "loss: 0.050266  [416064/500000]\n",
      "loss: 0.018204  [422464/500000]\n",
      "loss: 0.014598  [428864/500000]\n",
      "loss: 0.066294  [435264/500000]\n",
      "loss: 0.079890  [441664/500000]\n",
      "loss: 0.125924  [448064/500000]\n",
      "loss: 0.011172  [454464/500000]\n",
      "loss: 0.106324  [460864/500000]\n",
      "loss: 0.028862  [467264/500000]\n",
      "loss: 0.106307  [473664/500000]\n",
      "loss: 0.079798  [480064/500000]\n",
      "loss: 0.040822  [486464/500000]\n",
      "loss: 0.083474  [492864/500000]\n",
      "loss: 0.034672  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.043231 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.055483  [   64/500000]\n",
      "loss: 0.021118  [ 6464/500000]\n",
      "loss: 0.088004  [12864/500000]\n",
      "loss: 0.087762  [19264/500000]\n",
      "loss: 0.080425  [25664/500000]\n",
      "loss: 0.071034  [32064/500000]\n",
      "loss: 0.095374  [38464/500000]\n",
      "loss: 0.055538  [44864/500000]\n",
      "loss: 0.069273  [51264/500000]\n",
      "loss: 0.085272  [57664/500000]\n",
      "loss: 0.021634  [64064/500000]\n",
      "loss: 0.062835  [70464/500000]\n",
      "loss: 0.068207  [76864/500000]\n",
      "loss: 0.082403  [83264/500000]\n",
      "loss: 0.016533  [89664/500000]\n",
      "loss: 0.041884  [96064/500000]\n",
      "loss: 0.036001  [102464/500000]\n",
      "loss: 0.013197  [108864/500000]\n",
      "loss: 0.070623  [115264/500000]\n",
      "loss: 0.012124  [121664/500000]\n",
      "loss: 0.048269  [128064/500000]\n",
      "loss: 0.101789  [134464/500000]\n",
      "loss: 0.031938  [140864/500000]\n",
      "loss: 0.089049  [147264/500000]\n",
      "loss: 0.063605  [153664/500000]\n",
      "loss: 0.076892  [160064/500000]\n",
      "loss: 0.066309  [166464/500000]\n",
      "loss: 0.023548  [172864/500000]\n",
      "loss: 0.029250  [179264/500000]\n",
      "loss: 0.049928  [185664/500000]\n",
      "loss: 0.037222  [192064/500000]\n",
      "loss: 0.016529  [198464/500000]\n",
      "loss: 0.074234  [204864/500000]\n",
      "loss: 0.112328  [211264/500000]\n",
      "loss: 0.059985  [217664/500000]\n",
      "loss: 0.056558  [224064/500000]\n",
      "loss: 0.064527  [230464/500000]\n",
      "loss: 0.130160  [236864/500000]\n",
      "loss: 0.061063  [243264/500000]\n",
      "loss: 0.045451  [249664/500000]\n",
      "loss: 0.047535  [256064/500000]\n",
      "loss: 0.034468  [262464/500000]\n",
      "loss: 0.070664  [268864/500000]\n",
      "loss: 0.039386  [275264/500000]\n",
      "loss: 0.071447  [281664/500000]\n",
      "loss: 0.059887  [288064/500000]\n",
      "loss: 0.048350  [294464/500000]\n",
      "loss: 0.082207  [300864/500000]\n",
      "loss: 0.053863  [307264/500000]\n",
      "loss: 0.035995  [313664/500000]\n",
      "loss: 0.048561  [320064/500000]\n",
      "loss: 0.066315  [326464/500000]\n",
      "loss: 0.066699  [332864/500000]\n",
      "loss: 0.026380  [339264/500000]\n",
      "loss: 0.019894  [345664/500000]\n",
      "loss: 0.037567  [352064/500000]\n",
      "loss: 0.055232  [358464/500000]\n",
      "loss: 0.043079  [364864/500000]\n",
      "loss: 0.083109  [371264/500000]\n",
      "loss: 0.041780  [377664/500000]\n",
      "loss: 0.054956  [384064/500000]\n",
      "loss: 0.013844  [390464/500000]\n",
      "loss: 0.037969  [396864/500000]\n",
      "loss: 0.056504  [403264/500000]\n",
      "loss: 0.032650  [409664/500000]\n",
      "loss: 0.077166  [416064/500000]\n",
      "loss: 0.036694  [422464/500000]\n",
      "loss: 0.057791  [428864/500000]\n",
      "loss: 0.075370  [435264/500000]\n",
      "loss: 0.064118  [441664/500000]\n",
      "loss: 0.048774  [448064/500000]\n",
      "loss: 0.038412  [454464/500000]\n",
      "loss: 0.118690  [460864/500000]\n",
      "loss: 0.017315  [467264/500000]\n",
      "loss: 0.028689  [473664/500000]\n",
      "loss: 0.039921  [480064/500000]\n",
      "loss: 0.055314  [486464/500000]\n",
      "loss: 0.095500  [492864/500000]\n",
      "loss: 0.022900  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.043757 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.025615  [   64/500000]\n",
      "loss: 0.048910  [ 6464/500000]\n",
      "loss: 0.028127  [12864/500000]\n",
      "loss: 0.011980  [19264/500000]\n",
      "loss: 0.035657  [25664/500000]\n",
      "loss: 0.054651  [32064/500000]\n",
      "loss: 0.041854  [38464/500000]\n",
      "loss: 0.022827  [44864/500000]\n",
      "loss: 0.059334  [51264/500000]\n",
      "loss: 0.092686  [57664/500000]\n",
      "loss: 0.014537  [64064/500000]\n",
      "loss: 0.007440  [70464/500000]\n",
      "loss: 0.046343  [76864/500000]\n",
      "loss: 0.115141  [83264/500000]\n",
      "loss: 0.066052  [89664/500000]\n",
      "loss: 0.040102  [96064/500000]\n",
      "loss: 0.065502  [102464/500000]\n",
      "loss: 0.051881  [108864/500000]\n",
      "loss: 0.038685  [115264/500000]\n",
      "loss: 0.065381  [121664/500000]\n",
      "loss: 0.026265  [128064/500000]\n",
      "loss: 0.074037  [134464/500000]\n",
      "loss: 0.037281  [140864/500000]\n",
      "loss: 0.035213  [147264/500000]\n",
      "loss: 0.120371  [153664/500000]\n",
      "loss: 0.063579  [160064/500000]\n",
      "loss: 0.068581  [166464/500000]\n",
      "loss: 0.035390  [172864/500000]\n",
      "loss: 0.123438  [179264/500000]\n",
      "loss: 0.020237  [185664/500000]\n",
      "loss: 0.041204  [192064/500000]\n",
      "loss: 0.124344  [198464/500000]\n",
      "loss: 0.062185  [204864/500000]\n",
      "loss: 0.010475  [211264/500000]\n",
      "loss: 0.045844  [217664/500000]\n",
      "loss: 0.039786  [224064/500000]\n",
      "loss: 0.067372  [230464/500000]\n",
      "loss: 0.055821  [236864/500000]\n",
      "loss: 0.037345  [243264/500000]\n",
      "loss: 0.033838  [249664/500000]\n",
      "loss: 0.063771  [256064/500000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.035704  [262464/500000]\n",
      "loss: 0.005124  [268864/500000]\n",
      "loss: 0.049581  [275264/500000]\n",
      "loss: 0.019751  [281664/500000]\n",
      "loss: 0.022408  [288064/500000]\n",
      "loss: 0.055038  [294464/500000]\n",
      "loss: 0.040868  [300864/500000]\n",
      "loss: 0.018371  [307264/500000]\n",
      "loss: 0.086306  [313664/500000]\n",
      "loss: 0.009909  [320064/500000]\n",
      "loss: 0.044370  [326464/500000]\n",
      "loss: 0.029228  [332864/500000]\n",
      "loss: 0.107885  [339264/500000]\n",
      "loss: 0.080353  [345664/500000]\n",
      "loss: 0.038020  [352064/500000]\n",
      "loss: 0.043784  [358464/500000]\n",
      "loss: 0.037741  [364864/500000]\n",
      "loss: 0.016938  [371264/500000]\n",
      "loss: 0.020479  [377664/500000]\n",
      "loss: 0.039307  [384064/500000]\n",
      "loss: 0.079852  [390464/500000]\n",
      "loss: 0.028238  [396864/500000]\n",
      "loss: 0.039414  [403264/500000]\n",
      "loss: 0.087225  [409664/500000]\n",
      "loss: 0.006330  [416064/500000]\n",
      "loss: 0.025561  [422464/500000]\n",
      "loss: 0.069156  [428864/500000]\n",
      "loss: 0.037948  [435264/500000]\n",
      "loss: 0.022846  [441664/500000]\n",
      "loss: 0.042681  [448064/500000]\n",
      "loss: 0.045717  [454464/500000]\n",
      "loss: 0.046066  [460864/500000]\n",
      "loss: 0.076198  [467264/500000]\n",
      "loss: 0.035653  [473664/500000]\n",
      "loss: 0.170480  [480064/500000]\n",
      "loss: 0.051145  [486464/500000]\n",
      "loss: 0.036744  [492864/500000]\n",
      "loss: 0.051571  [499264/500000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.048614 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Training the Models\n",
    "epochs = 10 #here we try to improve the neuro network model\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9118b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9757\n",
      "Accuracy: 0.9749\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the Model\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        pred = model(X)\n",
    "        all_preds.extend(pred.argmax(dim=1).cpu().numpy())  # Collect predictions\n",
    "        all_targets.extend(y.cpu().numpy())  # Collect true labels\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2bd058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#according to last homework, a single decision tree model produces the F1 score 0.9998, while here we can\n",
    "#produce F1 score 0.98. Therefore a simple decision tree is better than the neural network model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a8ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
